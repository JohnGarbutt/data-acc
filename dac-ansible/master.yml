---
- name: Configure proxy's keys
  hosts: all
  gather_facts: false
  tasks:
    - name: Wait for proxy
      wait_for:
        host: "{{ ssh_proxy }}"
        port: 22
        state: started
        timeout: 360
      delegate_to: "localhost"

    - name: Scan for proxy's SSH keys
      command: "ssh-keyscan -t rsa {{ ssh_proxy }}"
      register: keyscan_results
      changed_when: False
      delegate_to: "localhost"

    - name: Ensure proxy in SSH known hosts
      blockinfile:
        block: |
          {% for line in keyscan_results.stdout_lines %}
          {{ line }}
          {% endfor %}
        create: true
        marker: "# {mark} MANAGED BLOCK FOR OpenHPC.proxy.{{ ssh_proxy }}"
        path: "~/.ssh/known_hosts"
      delegate_to: "localhost"

- name: Configure server's keys
  hosts: all
  vars:
    all_hosts: "{{ groups['all'] }}"
  gather_facts: false
  tasks:
    - name: Scan for server's SSH keys
      command: "ssh {{ ansible_user }}@{{ ssh_proxy }} ssh-keyscan -t rsa {{ ansible_host }}"
      register: keyscan_results
      changed_when: False
      delegate_to: "localhost"

    - name: Ensure servers are in SSH known hosts
      blockinfile:
        block: |
          {% for key in keyscan_results.stdout_lines %}
          {{ key }}
          {% endfor %}
        create: true
        marker: "# {mark} MANAGED BLOCK FOR OpenHPC.{{ inventory_hostname }}"
        path: "~/.ssh/known_hosts"
      delegate_to: "localhost"

- hosts: all
  become: true
  tasks:
  - name: Create entries in /etc/hosts for all nodes
    lineinfile:
      path: /etc/hosts
      line: "{{ hostvars[item]['ansible_host'] }} {{ hostvars[item]['ansible_hostname'] }} {{ item }}"
      regexp: "^.* {{ item }}$"
      create: no
      state: present
    with_items:
      - "{{ ansible_play_hosts }}"
  - name: Update all packages
    yum:
      name: "*"
      state: latest

- hosts: nfs
  become: true
  vars:
      nfs_exports: ["/home/cluster *(rw,sync,no_root_squash)"]
  tasks:
  - name: Create NFS directory
    file:
      path: /home/cluster
      state: directory
  roles:
    - geerlingguy.nfs

- hosts: openstack
  become: true
  tasks:
  - name: Create NFS directory
    file:
      path: /home/cluster
      state: directory
  - name: Mount NFS
    mount:
      path: /home/cluster
      state: "{{ item }}"
      src: "{{ groups.slurm_master | first }}:/home/cluster"
      fstype: nfs
      opts: _netdev
    when: "'nfs' not in group_names"
    with_items: [ present, mounted ]
  - name: Create test users
    user:
      name: "test{{ item }}"
      home: "/home/cluster/test{{ item }}"
    with_sequence: count=10

- hosts: etcd_master[0]
  roles:
    - role: andrewrothstein.pki
      pki_dir: /home/centos/pki-dir
      pki_self_sign: True
      pki_ca:
        cname: ca.dac.hpc.cam.ac.uk
      pki_servers:
        - cname: dac-etcd.dac.hpc.cam.ac.uk
          include_localhost: True
          sans:
            - dac-etcd.dac.hpc.cam.ac.uk
          altips:
            - "{{ hostvars[groups['etcd_master'][0]].ansible_host }}"
        - cname: dac1.dac.hpc.cam.ac.uk
          include_localhost: True
          sans:
            - dac1.dac.hpc.cam.ac.uk
        - cname: dac2.dac.hpc.cam.ac.uk
          include_localhost: True
          sans:
            - dac2.dac.hpc.cam.ac.uk
        - cname: dac3.dac.hpc.cam.ac.uk
          include_localhost: True
          sans:
            - dac3.dac.hpc.cam.ac.uk
        - cname: dac-slurm-master.dac.hpc.cam.ac.uk
          include_localhost: True
          sans:
            - dac-slurm-master.dac.hpc.cam.ac.uk
        - cname: slurm-cpu1.dac.hpc.cam.ac.uk
          include_localhost: True
          sans:
            - slurm-cpu1.dac.hpc.cam.ac.uk
        - cname: slurm-cpu2.dac.hpc.cam.ac.uk
          include_localhost: True
          sans:
            - slurm-cpu2.dac.hpc.cam.ac.uk

- hosts: etcd_master[0]
  tasks:
    - fetch:
        src: /home/centos/pki-dir/{{item}}
        dest: "{{ inventory_dir }}/pki-dir/"
        flat: yes
      with_items:
        - ca.pem
        - ca-key.pem
        - dac-etcd.dac.hpc.cam.ac.uk.pem
        - dac-etcd.dac.hpc.cam.ac.uk-key.pem
        - dac1.dac.hpc.cam.ac.uk.pem
        - dac1.dac.hpc.cam.ac.uk-key.pem
        - dac2.dac.hpc.cam.ac.uk.pem
        - dac2.dac.hpc.cam.ac.uk-key.pem
        - dac3.dac.hpc.cam.ac.uk.pem
        - dac3.dac.hpc.cam.ac.uk-key.pem
        - dac-slurm-master.dac.hpc.cam.ac.uk.pem
        - dac-slurm-master.dac.hpc.cam.ac.uk-key.pem
        - slurm-cpu1.dac.hpc.cam.ac.uk.pem
        - slurm-cpu1.dac.hpc.cam.ac.uk-key.pem
        - slurm-cpu2.dac.hpc.cam.ac.uk.pem
        - slurm-cpu2.dac.hpc.cam.ac.uk-key.pem

- hosts: etcd
  roles:
    - role: andrewrothstein.etcd-cluster
      etcd_master_group_name: etcd_master
      etcd_pki_dir: "{{ inventory_dir }}/pki-dir"

- hosts: dac_workers:slurm_workers
  become: true
  roles:
    - geerlingguy.repo-epel
    - geerlingguy.pip

- hosts: dac_workers
  become: True
  tasks:
    - name: ensure kernel dev tools available for beegfs client autobuild
      package:
        name: kernel-devel
    - name: ensure dev tools available for beegfs client autobuild
      package:
        name: gcc
    - selinux:
        state: disabled

# TODO: should this be part of fs-ansible really?
- hosts: dac_workers:slurm_workers
  become: True
  vars:
      lustre_release: "2.12.2"
  tasks:
    - name: enable lustre server repo
      yum_repository:
        name: lustre-server
        description: lustre-server
        file: lustre-repo
        baseurl: https://downloads.whamcloud.com/public/lustre/lustre-{{ lustre_release }}/el7/patchless-ldiskfs-server
        gpgcheck: no
    - name: enable lustre client repo
      yum_repository:
        name: lustre-client
        description: lustre-client
        file: lustre-repo
        baseurl: https://downloads.whamcloud.com/public/lustre/lustre-{{ lustre_release }}/el7/client
        gpgcheck: no
    - name: enable lustre e2fs repo
      yum_repository:
        name: e2fsprogs-wc
        description: e2fsprogs-wc
        file: lustre-repo
        baseurl: https://downloads.whamcloud.com/public/e2fsprogs/latest/el7
        gpgcheck: no

- hosts: dac_workers:slurm_workers
  become: True
  vars:
      lustre_release: "2.12.2"
  tasks:
    - name: Install Lustre Server
      yum:
        name: "lustre-{{ lustre_release }}"
        state: present
    - name: Install LVM
      yum:
        name: "lvm2"
        state: present

- hosts: dac_workers:slurm_workers
  become: True
  vars:
      lustre_release: "2.12.2"
  tasks:
    - name: Install Lustre Client
      yum:
        name: "lustre-client-dkms-{{ lustre_release }}"
        state: present

- hosts: dac_workers
  become: true
  become_user: root
  roles:
    - role: data-acc

- hosts: dac_workers[0]
  become: true
  become_user: dac
  tasks:
    - name: Create ssh key for dac user for fs-ansible
      shell: |
        ssh-keygen -f /var/lib/dac/.ssh/id_rsa -t rsa -N ''
        cat /var/lib/dac/.ssh/id_rsa.pub >> /var/lib/dac/.ssh/authorized_keys
      args:
         creates: /var/lib/dac/.ssh/id_rsa
    - name: Pull Keys
      synchronize:
        mode: pull
        src:  /var/lib/dac/.ssh/
        dest: "{{ inventory_dir }}/.dac.ssh/"
        recursive: yes
        delete: yes

- hosts: dac_workers:slurm_workers
  become: true
  tasks:
    - name: create data_acc group
      become: yes
      become_user: root
      group:
        name: dac
        state: present
    - name: create data_acc group
      become: yes
      become_user: root
      group:
        name: etcd
        state: present
    - name: create data_acc user
      become: yes
      become_user: root
      user:
        name: dac
        group: dac
        groups: etcd,wheel # Get access to etcd private key, and sudo for ansible
        home: /var/lib/dac
        state: present
    - name: Push Keys for dac user for fs-ansible
      synchronize:
        mode: push
        src: "{{ inventory_dir }}/.dac.ssh/"
        dest:  /var/lib/dac/.ssh/
        recursive: yes
    - name: trust host keys
      shell: |
        ssh-keyscan {{ hostvars[item]['ansible_host'] }} >> /var/lib/dac/.ssh/known_hosts
        ssh-keyscan {{ hostvars[item]['ansible_hostname'] }} >> /var/lib/dac/.ssh/known_hosts
        ssh-keyscan {{ item }} >> /var/lib/dac/.ssh/known_hosts
        touch /var/lib/dac/.ssh/.known{{ hostvars[item]['ansible_host'] }}
      args:
         creates: "/var/lib/dac/.ssh/.known{{ hostvars[item]['ansible_host'] }}"
      with_items: "{{ ansible_play_hosts }}"
    - name: Fix up permissions on .ssh
      file:
        path: /var/lib/dac/.ssh
        owner: dac
        group: dac
        recurse: yes

- hosts: dac_workers
  become: true
  tasks:
    - name: Ensure passwordless sudo for dac user
      lineinfile:
        path: /etc/sudoers.d/80-dac
        line: "dac ALL=(ALL) NOPASSWD:ALL"
        regexp: "^dac.*$"
        create: yes
        state: present

- hosts: slurm_workers
  become: true
  tasks:
    - name: Ensure passwordless sudo for dac user
      lineinfile:
        path: /etc/sudoers.d/80-dac
        line: "dac ALL=(ALL) NOPASSWD: /usr/bin/mkdir -p /mnt/dac/*, /usr/bin/chmod 700 /mnt/dac/*, /usr/bin/chmod 0600 /mnt/dac/*, /usr/bin/chown * /mnt/dac/*, /usr/bin/mount -t lustre * /mnt/dac/*, /usr/bin/umount /mnt/dac/*, /usr/sbin/losetup /dev/loop* /mnt/dac/*, /usr/sbin/losetup -d /dev/loop*, /usr/sbin/mkswap /dev/loop*, /usr/sbin/swapon /dev/loop*, /usr/sbin/swapoff /dev/loop*, /usr/bin/ln -s /mnt/dac/* /mnt/dac/*, /usr/bin/dd if=/dev/zero of=/dac/*, /usr/bin/rm -df /mnt/dac/*, /bin/grep /mnt/dac/* /etc/mtab"
        regexp: "^dac.*$"
        create: yes
        state: present

- hosts: slurm
  become: true
  roles:
    - geerlingguy.repo-epel
    - geerlingguy.pip
    - data-acc
    - slurm-ansible

- hosts: slurm_master[0]
  become: true
  vars:
      recreate: false
  tasks:
    - file:
        path: /etc/data-acc/pki
        state: directory
        mode: 0700
        owner: '8900'
        group: '8900'
    - name: copy etcd keys
      become: yes
      become_user: root
      copy:
        src: '{{item}}'
        dest: /etc/data-acc/pki
        owner: '8900' # TODO...
        group: '8900'
        mode: 0700
      with_items:
        - '{{ inventory_dir }}/pki-dir/{{inventory_hostname}}.pem'
        - '{{ inventory_dir }}/pki-dir/{{inventory_hostname}}-key.pem'
        - '{{ inventory_dir }}/pki-dir/ca.pem'

- hosts: slurm_workers
  become: true
  vars:
      recreate: false
  tasks:
    - file:
        path: /etc/data-acc/pki
        state: directory
        mode: 0700
        owner: root
        group: root
    - name: copy etcd keys
      become: yes
      become_user: root
      copy:
        src: '{{item}}'
        dest: /etc/data-acc/pki
        owner: 'root' # TODO...
        group: 'root'
        mode: 0700
      with_items:
        - '{{ inventory_dir }}/pki-dir/{{inventory_hostname}}.pem'
        - '{{ inventory_dir }}/pki-dir/{{inventory_hostname}}-key.pem'
        - '{{ inventory_dir }}/pki-dir/ca.pem'
